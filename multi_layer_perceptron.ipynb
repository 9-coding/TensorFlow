{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNS54VnEJ7T5q+86PFcMmVM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/9-coding/TensorFlow/blob/main/multi_layer_perceptron.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rux8pOfZnmPT",
        "outputId": "5f7cd1ad-31a0-4030-e7f2-dabe571e7f7d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "469/469 - 6s - loss: 0.0906 - accuracy: 0.1346 - val_loss: 0.0882 - val_accuracy: 0.2134 - 6s/epoch - 13ms/step\n",
            "Epoch 2/50\n",
            "469/469 - 5s - loss: 0.0855 - accuracy: 0.3002 - val_loss: 0.0823 - val_accuracy: 0.4007 - 5s/epoch - 10ms/step\n",
            "Epoch 3/50\n",
            "469/469 - 5s - loss: 0.0788 - accuracy: 0.4505 - val_loss: 0.0749 - val_accuracy: 0.5007 - 5s/epoch - 10ms/step\n",
            "Epoch 4/50\n",
            "469/469 - 4s - loss: 0.0714 - accuracy: 0.5430 - val_loss: 0.0675 - val_accuracy: 0.5981 - 4s/epoch - 8ms/step\n",
            "Epoch 5/50\n",
            "469/469 - 4s - loss: 0.0644 - accuracy: 0.6285 - val_loss: 0.0605 - val_accuracy: 0.6740 - 4s/epoch - 8ms/step\n",
            "Epoch 6/50\n",
            "469/469 - 5s - loss: 0.0580 - accuracy: 0.6942 - val_loss: 0.0544 - val_accuracy: 0.7277 - 5s/epoch - 11ms/step\n",
            "Epoch 7/50\n",
            "469/469 - 4s - loss: 0.0525 - accuracy: 0.7348 - val_loss: 0.0492 - val_accuracy: 0.7601 - 4s/epoch - 9ms/step\n",
            "Epoch 8/50\n",
            "469/469 - 4s - loss: 0.0479 - accuracy: 0.7606 - val_loss: 0.0450 - val_accuracy: 0.7823 - 4s/epoch - 9ms/step\n",
            "Epoch 9/50\n",
            "469/469 - 5s - loss: 0.0442 - accuracy: 0.7794 - val_loss: 0.0415 - val_accuracy: 0.7980 - 5s/epoch - 11ms/step\n",
            "Epoch 10/50\n",
            "469/469 - 4s - loss: 0.0411 - accuracy: 0.7936 - val_loss: 0.0387 - val_accuracy: 0.8095 - 4s/epoch - 9ms/step\n",
            "Epoch 11/50\n",
            "469/469 - 4s - loss: 0.0386 - accuracy: 0.8041 - val_loss: 0.0363 - val_accuracy: 0.8219 - 4s/epoch - 9ms/step\n",
            "Epoch 12/50\n",
            "469/469 - 5s - loss: 0.0364 - accuracy: 0.8130 - val_loss: 0.0343 - val_accuracy: 0.8306 - 5s/epoch - 10ms/step\n",
            "Epoch 13/50\n",
            "469/469 - 5s - loss: 0.0346 - accuracy: 0.8204 - val_loss: 0.0326 - val_accuracy: 0.8371 - 5s/epoch - 10ms/step\n",
            "Epoch 14/50\n",
            "469/469 - 5s - loss: 0.0331 - accuracy: 0.8268 - val_loss: 0.0312 - val_accuracy: 0.8434 - 5s/epoch - 11ms/step\n",
            "Epoch 15/50\n",
            "469/469 - 4s - loss: 0.0317 - accuracy: 0.8327 - val_loss: 0.0299 - val_accuracy: 0.8485 - 4s/epoch - 8ms/step\n",
            "Epoch 16/50\n",
            "469/469 - 5s - loss: 0.0306 - accuracy: 0.8379 - val_loss: 0.0288 - val_accuracy: 0.8531 - 5s/epoch - 11ms/step\n",
            "Epoch 17/50\n",
            "469/469 - 5s - loss: 0.0295 - accuracy: 0.8421 - val_loss: 0.0279 - val_accuracy: 0.8565 - 5s/epoch - 12ms/step\n",
            "Epoch 18/50\n",
            "469/469 - 4s - loss: 0.0286 - accuracy: 0.8462 - val_loss: 0.0270 - val_accuracy: 0.8605 - 4s/epoch - 9ms/step\n",
            "Epoch 19/50\n",
            "469/469 - 4s - loss: 0.0278 - accuracy: 0.8493 - val_loss: 0.0262 - val_accuracy: 0.8638 - 4s/epoch - 8ms/step\n",
            "Epoch 20/50\n",
            "469/469 - 5s - loss: 0.0271 - accuracy: 0.8523 - val_loss: 0.0256 - val_accuracy: 0.8666 - 5s/epoch - 11ms/step\n",
            "Epoch 21/50\n",
            "469/469 - 4s - loss: 0.0264 - accuracy: 0.8549 - val_loss: 0.0249 - val_accuracy: 0.8687 - 4s/epoch - 8ms/step\n",
            "Epoch 22/50\n",
            "469/469 - 4s - loss: 0.0258 - accuracy: 0.8571 - val_loss: 0.0244 - val_accuracy: 0.8713 - 4s/epoch - 8ms/step\n",
            "Epoch 23/50\n",
            "469/469 - 5s - loss: 0.0253 - accuracy: 0.8594 - val_loss: 0.0239 - val_accuracy: 0.8725 - 5s/epoch - 11ms/step\n",
            "Epoch 24/50\n",
            "469/469 - 4s - loss: 0.0248 - accuracy: 0.8614 - val_loss: 0.0234 - val_accuracy: 0.8738 - 4s/epoch - 8ms/step\n",
            "Epoch 25/50\n",
            "469/469 - 4s - loss: 0.0243 - accuracy: 0.8636 - val_loss: 0.0230 - val_accuracy: 0.8752 - 4s/epoch - 9ms/step\n",
            "Epoch 26/50\n",
            "469/469 - 5s - loss: 0.0239 - accuracy: 0.8656 - val_loss: 0.0226 - val_accuracy: 0.8772 - 5s/epoch - 11ms/step\n",
            "Epoch 27/50\n",
            "469/469 - 4s - loss: 0.0235 - accuracy: 0.8668 - val_loss: 0.0222 - val_accuracy: 0.8782 - 4s/epoch - 9ms/step\n",
            "Epoch 28/50\n",
            "469/469 - 4s - loss: 0.0232 - accuracy: 0.8682 - val_loss: 0.0219 - val_accuracy: 0.8793 - 4s/epoch - 8ms/step\n",
            "Epoch 29/50\n",
            "469/469 - 5s - loss: 0.0228 - accuracy: 0.8695 - val_loss: 0.0216 - val_accuracy: 0.8811 - 5s/epoch - 10ms/step\n",
            "Epoch 30/50\n",
            "469/469 - 4s - loss: 0.0225 - accuracy: 0.8707 - val_loss: 0.0213 - val_accuracy: 0.8816 - 4s/epoch - 8ms/step\n",
            "Epoch 31/50\n",
            "469/469 - 4s - loss: 0.0222 - accuracy: 0.8716 - val_loss: 0.0210 - val_accuracy: 0.8827 - 4s/epoch - 8ms/step\n",
            "Epoch 32/50\n",
            "469/469 - 5s - loss: 0.0220 - accuracy: 0.8731 - val_loss: 0.0207 - val_accuracy: 0.8838 - 5s/epoch - 10ms/step\n",
            "Epoch 33/50\n",
            "469/469 - 4s - loss: 0.0217 - accuracy: 0.8740 - val_loss: 0.0205 - val_accuracy: 0.8851 - 4s/epoch - 8ms/step\n",
            "Epoch 34/50\n",
            "469/469 - 4s - loss: 0.0215 - accuracy: 0.8751 - val_loss: 0.0202 - val_accuracy: 0.8863 - 4s/epoch - 8ms/step\n",
            "Epoch 35/50\n",
            "469/469 - 5s - loss: 0.0212 - accuracy: 0.8759 - val_loss: 0.0200 - val_accuracy: 0.8871 - 5s/epoch - 10ms/step\n",
            "Epoch 36/50\n",
            "469/469 - 4s - loss: 0.0210 - accuracy: 0.8771 - val_loss: 0.0198 - val_accuracy: 0.8878 - 4s/epoch - 9ms/step\n",
            "Epoch 37/50\n",
            "469/469 - 4s - loss: 0.0208 - accuracy: 0.8779 - val_loss: 0.0196 - val_accuracy: 0.8887 - 4s/epoch - 9ms/step\n",
            "Epoch 38/50\n",
            "469/469 - 5s - loss: 0.0206 - accuracy: 0.8788 - val_loss: 0.0194 - val_accuracy: 0.8894 - 5s/epoch - 10ms/step\n",
            "Epoch 39/50\n",
            "469/469 - 4s - loss: 0.0204 - accuracy: 0.8796 - val_loss: 0.0193 - val_accuracy: 0.8900 - 4s/epoch - 8ms/step\n",
            "Epoch 40/50\n",
            "469/469 - 4s - loss: 0.0202 - accuracy: 0.8803 - val_loss: 0.0191 - val_accuracy: 0.8912 - 4s/epoch - 9ms/step\n",
            "Epoch 41/50\n",
            "469/469 - 5s - loss: 0.0201 - accuracy: 0.8809 - val_loss: 0.0189 - val_accuracy: 0.8919 - 5s/epoch - 11ms/step\n",
            "Epoch 42/50\n",
            "469/469 - 5s - loss: 0.0199 - accuracy: 0.8816 - val_loss: 0.0188 - val_accuracy: 0.8925 - 5s/epoch - 10ms/step\n",
            "Epoch 43/50\n",
            "469/469 - 6s - loss: 0.0197 - accuracy: 0.8822 - val_loss: 0.0186 - val_accuracy: 0.8926 - 6s/epoch - 13ms/step\n",
            "Epoch 44/50\n",
            "469/469 - 4s - loss: 0.0196 - accuracy: 0.8829 - val_loss: 0.0185 - val_accuracy: 0.8930 - 4s/epoch - 9ms/step\n",
            "Epoch 45/50\n",
            "469/469 - 4s - loss: 0.0195 - accuracy: 0.8835 - val_loss: 0.0183 - val_accuracy: 0.8940 - 4s/epoch - 9ms/step\n",
            "Epoch 46/50\n",
            "469/469 - 5s - loss: 0.0193 - accuracy: 0.8839 - val_loss: 0.0182 - val_accuracy: 0.8950 - 5s/epoch - 11ms/step\n",
            "Epoch 47/50\n",
            "469/469 - 4s - loss: 0.0192 - accuracy: 0.8846 - val_loss: 0.0181 - val_accuracy: 0.8952 - 4s/epoch - 9ms/step\n",
            "Epoch 48/50\n",
            "469/469 - 4s - loss: 0.0190 - accuracy: 0.8853 - val_loss: 0.0180 - val_accuracy: 0.8958 - 4s/epoch - 9ms/step\n",
            "Epoch 49/50\n",
            "469/469 - 5s - loss: 0.0189 - accuracy: 0.8858 - val_loss: 0.0178 - val_accuracy: 0.8964 - 5s/epoch - 11ms/step\n",
            "Epoch 50/50\n",
            "469/469 - 4s - loss: 0.0188 - accuracy: 0.8863 - val_loss: 0.0177 - val_accuracy: 0.8966 - 4s/epoch - 9ms/step\n",
            "정확도= 89.66000080108643\n"
          ]
        }
      ],
      "source": [
        "# SGD optimizer\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras.datasets as ds\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "\n",
        "# 데이터 준비\n",
        "(x_train, y_train), (x_test, y_test)=ds.mnist.load_data()\n",
        "# 28x28을 784로 펼침.\n",
        "x_train=x_train.reshape(60000, 784)\n",
        "x_test=x_test.reshape(10000, 784)\n",
        "# 원래 데이터형 unit8을 실수 연산을 위해 float32로 변환, [0,255] 범위를 [0,1]로.\n",
        "x_train=x_train.astype(np.float32)/255.0\n",
        "x_test=x_test.astype(np.float32)/255.0\n",
        "# 0~9 사이의 정수로 표현된 것을 one-hot-vector로 변환.\n",
        "y_train=tf.keras.utils.to_categorical(y_train,10)\n",
        "y_test=tf.keras.utils.to_categorical(y_test,10)\n",
        "\n",
        "# 모델 구성\n",
        "mlp=Sequential()\n",
        "mlp.add(Dense(units=512, activation='tanh', input_shape=(784,))) # 은닉층에 512개, 입력층에 784개 노드 배치.\n",
        "mlp.add(Dense(units=10, activation='softmax')) # 출력층에 노드 10개 배치 (카테고리가 10개)\n",
        "\n",
        "# 학습\n",
        "# compile과 fit 동시에 사용.\n",
        "mlp.compile(loss='MSE', optimizer=SGD(learning_rate=0.01), metrics=['accuracy'])\n",
        "mlp.fit(x_train, y_train, batch_size=128, epochs=50, validation_data=(x_test, y_test), verbose=2)\n",
        "\n",
        "# 예측 및 성능 측정\n",
        "res=mlp.evaluate(x_test,y_test, verbose=0)\n",
        "print('정확도=', res[1]*100)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Adam optimizer\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras.datasets as ds\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# 데이터 준비\n",
        "(x_train, y_train), (x_test, y_test)=ds.mnist.load_data()\n",
        "# 28x28을 784로 펼침.\n",
        "x_train=x_train.reshape(60000, 784)\n",
        "x_test=x_test.reshape(10000, 784)\n",
        "# 원래 데이터형 unit8을 실수 연산을 위해 float32로 변환, [0,255] 범위를 [0,1]로.\n",
        "x_train=x_train.astype(np.float32)/255.0\n",
        "x_test=x_test.astype(np.float32)/255.0\n",
        "# 0~9 사이의 정수로 표현된 것을 one-hot-vector로 변환.\n",
        "y_train=tf.keras.utils.to_categorical(y_train,10)\n",
        "y_test=tf.keras.utils.to_categorical(y_test,10)\n",
        "\n",
        "# 모델 구성\n",
        "mlp=Sequential()\n",
        "mlp.add(Dense(units=512, activation='tanh', input_shape=(784,))) # 은닉층에 512개, 입력층에 784개 노드 배치.\n",
        "mlp.add(Dense(units=10, activation='softmax')) # 출력층에 노드 10개 배치 (카테고리가 10개)\n",
        "\n",
        "# 학습\n",
        "# compile과 fit 동시에 사용.\n",
        "mlp.compile(loss='MSE', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])\n",
        "mlp.fit(x_train, y_train, batch_size=128, epochs=50, validation_data=(x_test, y_test), verbose=2)\n",
        "\n",
        "# 예측 및 성능 측정\n",
        "res=mlp.evaluate(x_test,y_test, verbose=0)\n",
        "print('정확도=', res[1]*100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8IfyOTdqtAGW",
        "outputId": "f1442f03-286b-43c3-8e8b-28d994a34dcb"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "469/469 - 6s - loss: 0.0146 - accuracy: 0.9032 - val_loss: 0.0106 - val_accuracy: 0.9326 - 6s/epoch - 14ms/step\n",
            "Epoch 2/50\n",
            "469/469 - 5s - loss: 0.0087 - accuracy: 0.9435 - val_loss: 0.0078 - val_accuracy: 0.9489 - 5s/epoch - 10ms/step\n",
            "Epoch 3/50\n",
            "469/469 - 6s - loss: 0.0064 - accuracy: 0.9596 - val_loss: 0.0062 - val_accuracy: 0.9592 - 6s/epoch - 14ms/step\n",
            "Epoch 4/50\n",
            "469/469 - 5s - loss: 0.0050 - accuracy: 0.9683 - val_loss: 0.0051 - val_accuracy: 0.9682 - 5s/epoch - 11ms/step\n",
            "Epoch 5/50\n",
            "469/469 - 5s - loss: 0.0040 - accuracy: 0.9754 - val_loss: 0.0046 - val_accuracy: 0.9704 - 5s/epoch - 11ms/step\n",
            "Epoch 6/50\n",
            "469/469 - 5s - loss: 0.0033 - accuracy: 0.9805 - val_loss: 0.0042 - val_accuracy: 0.9729 - 5s/epoch - 11ms/step\n",
            "Epoch 7/50\n",
            "469/469 - 5s - loss: 0.0028 - accuracy: 0.9834 - val_loss: 0.0039 - val_accuracy: 0.9750 - 5s/epoch - 10ms/step\n",
            "Epoch 8/50\n",
            "469/469 - 5s - loss: 0.0024 - accuracy: 0.9863 - val_loss: 0.0039 - val_accuracy: 0.9743 - 5s/epoch - 11ms/step\n",
            "Epoch 9/50\n",
            "469/469 - 5s - loss: 0.0020 - accuracy: 0.9886 - val_loss: 0.0037 - val_accuracy: 0.9747 - 5s/epoch - 11ms/step\n",
            "Epoch 10/50\n",
            "469/469 - 7s - loss: 0.0017 - accuracy: 0.9905 - val_loss: 0.0034 - val_accuracy: 0.9782 - 7s/epoch - 15ms/step\n",
            "Epoch 11/50\n",
            "469/469 - 5s - loss: 0.0015 - accuracy: 0.9915 - val_loss: 0.0039 - val_accuracy: 0.9745 - 5s/epoch - 11ms/step\n",
            "Epoch 12/50\n",
            "469/469 - 6s - loss: 0.0013 - accuracy: 0.9930 - val_loss: 0.0031 - val_accuracy: 0.9801 - 6s/epoch - 13ms/step\n",
            "Epoch 13/50\n",
            "469/469 - 7s - loss: 0.0011 - accuracy: 0.9941 - val_loss: 0.0031 - val_accuracy: 0.9785 - 7s/epoch - 15ms/step\n",
            "Epoch 14/50\n",
            "469/469 - 6s - loss: 9.0270e-04 - accuracy: 0.9954 - val_loss: 0.0031 - val_accuracy: 0.9801 - 6s/epoch - 12ms/step\n",
            "Epoch 15/50\n",
            "469/469 - 5s - loss: 7.8867e-04 - accuracy: 0.9960 - val_loss: 0.0032 - val_accuracy: 0.9787 - 5s/epoch - 11ms/step\n",
            "Epoch 16/50\n",
            "469/469 - 6s - loss: 7.1933e-04 - accuracy: 0.9965 - val_loss: 0.0030 - val_accuracy: 0.9802 - 6s/epoch - 13ms/step\n",
            "Epoch 17/50\n",
            "469/469 - 5s - loss: 5.7506e-04 - accuracy: 0.9971 - val_loss: 0.0029 - val_accuracy: 0.9811 - 5s/epoch - 12ms/step\n",
            "Epoch 18/50\n",
            "469/469 - 6s - loss: 5.3833e-04 - accuracy: 0.9974 - val_loss: 0.0032 - val_accuracy: 0.9790 - 6s/epoch - 12ms/step\n",
            "Epoch 19/50\n",
            "469/469 - 6s - loss: 5.4369e-04 - accuracy: 0.9972 - val_loss: 0.0033 - val_accuracy: 0.9790 - 6s/epoch - 12ms/step\n",
            "Epoch 20/50\n",
            "469/469 - 5s - loss: 5.4090e-04 - accuracy: 0.9972 - val_loss: 0.0037 - val_accuracy: 0.9756 - 5s/epoch - 11ms/step\n",
            "Epoch 21/50\n",
            "469/469 - 6s - loss: 4.3018e-04 - accuracy: 0.9980 - val_loss: 0.0029 - val_accuracy: 0.9815 - 6s/epoch - 13ms/step\n",
            "Epoch 22/50\n",
            "469/469 - 6s - loss: 3.8920e-04 - accuracy: 0.9980 - val_loss: 0.0029 - val_accuracy: 0.9822 - 6s/epoch - 12ms/step\n",
            "Epoch 23/50\n",
            "469/469 - 6s - loss: 4.6895e-04 - accuracy: 0.9975 - val_loss: 0.0030 - val_accuracy: 0.9808 - 6s/epoch - 13ms/step\n",
            "Epoch 24/50\n",
            "469/469 - 5s - loss: 3.6977e-04 - accuracy: 0.9981 - val_loss: 0.0032 - val_accuracy: 0.9799 - 5s/epoch - 11ms/step\n",
            "Epoch 25/50\n",
            "469/469 - 5s - loss: 3.1246e-04 - accuracy: 0.9984 - val_loss: 0.0028 - val_accuracy: 0.9813 - 5s/epoch - 11ms/step\n",
            "Epoch 26/50\n",
            "469/469 - 5s - loss: 2.8159e-04 - accuracy: 0.9986 - val_loss: 0.0031 - val_accuracy: 0.9804 - 5s/epoch - 11ms/step\n",
            "Epoch 27/50\n",
            "469/469 - 6s - loss: 3.1863e-04 - accuracy: 0.9983 - val_loss: 0.0031 - val_accuracy: 0.9793 - 6s/epoch - 12ms/step\n",
            "Epoch 28/50\n",
            "469/469 - 6s - loss: 5.0522e-04 - accuracy: 0.9971 - val_loss: 0.0033 - val_accuracy: 0.9784 - 6s/epoch - 12ms/step\n",
            "Epoch 29/50\n",
            "469/469 - 5s - loss: 3.7722e-04 - accuracy: 0.9979 - val_loss: 0.0030 - val_accuracy: 0.9816 - 5s/epoch - 10ms/step\n",
            "Epoch 30/50\n",
            "469/469 - 6s - loss: 2.5513e-04 - accuracy: 0.9987 - val_loss: 0.0029 - val_accuracy: 0.9810 - 6s/epoch - 12ms/step\n",
            "Epoch 31/50\n",
            "469/469 - 5s - loss: 2.1057e-04 - accuracy: 0.9989 - val_loss: 0.0031 - val_accuracy: 0.9806 - 5s/epoch - 10ms/step\n",
            "Epoch 32/50\n",
            "469/469 - 6s - loss: 2.8657e-04 - accuracy: 0.9984 - val_loss: 0.0030 - val_accuracy: 0.9805 - 6s/epoch - 13ms/step\n",
            "Epoch 33/50\n",
            "469/469 - 5s - loss: 3.9552e-04 - accuracy: 0.9978 - val_loss: 0.0030 - val_accuracy: 0.9815 - 5s/epoch - 11ms/step\n",
            "Epoch 34/50\n",
            "469/469 - 5s - loss: 3.2049e-04 - accuracy: 0.9982 - val_loss: 0.0029 - val_accuracy: 0.9824 - 5s/epoch - 12ms/step\n",
            "Epoch 35/50\n",
            "469/469 - 6s - loss: 2.1644e-04 - accuracy: 0.9989 - val_loss: 0.0030 - val_accuracy: 0.9811 - 6s/epoch - 12ms/step\n",
            "Epoch 36/50\n",
            "469/469 - 5s - loss: 2.7366e-04 - accuracy: 0.9986 - val_loss: 0.0032 - val_accuracy: 0.9798 - 5s/epoch - 11ms/step\n",
            "Epoch 37/50\n",
            "469/469 - 7s - loss: 2.5105e-04 - accuracy: 0.9987 - val_loss: 0.0029 - val_accuracy: 0.9826 - 7s/epoch - 14ms/step\n",
            "Epoch 38/50\n",
            "469/469 - 6s - loss: 2.4223e-04 - accuracy: 0.9987 - val_loss: 0.0032 - val_accuracy: 0.9797 - 6s/epoch - 13ms/step\n",
            "Epoch 39/50\n",
            "469/469 - 6s - loss: 3.5490e-04 - accuracy: 0.9979 - val_loss: 0.0030 - val_accuracy: 0.9811 - 6s/epoch - 13ms/step\n",
            "Epoch 40/50\n",
            "469/469 - 5s - loss: 2.0979e-04 - accuracy: 0.9989 - val_loss: 0.0031 - val_accuracy: 0.9810 - 5s/epoch - 11ms/step\n",
            "Epoch 41/50\n",
            "469/469 - 6s - loss: 2.3295e-04 - accuracy: 0.9987 - val_loss: 0.0030 - val_accuracy: 0.9809 - 6s/epoch - 13ms/step\n",
            "Epoch 42/50\n",
            "469/469 - 5s - loss: 3.5178e-04 - accuracy: 0.9979 - val_loss: 0.0032 - val_accuracy: 0.9801 - 5s/epoch - 11ms/step\n",
            "Epoch 43/50\n",
            "469/469 - 5s - loss: 2.2071e-04 - accuracy: 0.9989 - val_loss: 0.0034 - val_accuracy: 0.9792 - 5s/epoch - 11ms/step\n",
            "Epoch 44/50\n",
            "469/469 - 5s - loss: 2.0277e-04 - accuracy: 0.9989 - val_loss: 0.0031 - val_accuracy: 0.9805 - 5s/epoch - 11ms/step\n",
            "Epoch 45/50\n",
            "469/469 - 5s - loss: 1.9419e-04 - accuracy: 0.9990 - val_loss: 0.0031 - val_accuracy: 0.9808 - 5s/epoch - 10ms/step\n",
            "Epoch 46/50\n",
            "469/469 - 6s - loss: 3.7004e-04 - accuracy: 0.9979 - val_loss: 0.0030 - val_accuracy: 0.9814 - 6s/epoch - 12ms/step\n",
            "Epoch 47/50\n",
            "469/469 - 5s - loss: 2.1884e-04 - accuracy: 0.9988 - val_loss: 0.0030 - val_accuracy: 0.9817 - 5s/epoch - 10ms/step\n",
            "Epoch 48/50\n",
            "469/469 - 6s - loss: 1.8252e-04 - accuracy: 0.9990 - val_loss: 0.0029 - val_accuracy: 0.9822 - 6s/epoch - 13ms/step\n",
            "Epoch 49/50\n",
            "469/469 - 5s - loss: 2.2556e-04 - accuracy: 0.9987 - val_loss: 0.0034 - val_accuracy: 0.9787 - 5s/epoch - 11ms/step\n",
            "Epoch 50/50\n",
            "469/469 - 4s - loss: 2.0631e-04 - accuracy: 0.9989 - val_loss: 0.0030 - val_accuracy: 0.9815 - 4s/epoch - 9ms/step\n",
            "정확도= 98.15000295639038\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Memo\n",
        "\n",
        "- metrics['accuracy']: 정확도를 기준으로 성능 측정\n",
        "- verbose: 학습 도중 출력 지시 (0: 출력x / 1: 진행 막대만 표시 / 2: 학습 도중 epoch마다 성능 출력)\n",
        "- 학습 시간을 측정하려면 fit 앞뒤에서 time.time()으로 시간을 재서 빼면 됨."
      ],
      "metadata": {
        "id": "bv0U3EKktAK_"
      }
    }
  ]
}